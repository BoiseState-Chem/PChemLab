{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr Oliviero Andreussi, olivieroandreuss@boisestate.edu\n",
    "\n",
    "Boise State University, Department of Chemistry and Biochemistry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and Data Analysis for the Differential Scanning Calorimetry Experiment {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Setup {-}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let us import the main modules that we will need for this lecture. You may see some new modules in the list below, we will add more details in the right sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Notebook Setup { display-mode: \"form\" }\n",
    "# Import the main modules used in this worksheet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import medfilt\n",
    "from scipy.integrate import simps, cumulative_trapezoid\n",
    "# Load the google drive with your files \n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# The following needs to be the path of the folder with all your datafile in .csv format\n",
    "base_path = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions to load the data { display-mode: \"form\" }\n",
    "def load_data_to_file_dict(file_dict):\n",
    "    \"\"\"\n",
    "    Load a DSC .txt file. \n",
    "    The format of the file should have two rows of headers, one extra line of text at the end, and five columns of data\n",
    "    The columns are: index, time, heat flow, temperature of sample, temperature of reference\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Add to file_dict a Pandas DataFrame with four columns: time (in seconds), heat flow (in W/g), \n",
    "        temperature of sample (in C), and temperature of reference (in C)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_dict['path']+file_dict['name'],skiprows=2,skipfooter=1,names=['Time','Heat-Flow','Ts','Tr'],sep=' +',index_col=0,engine='python',encoding='unicode_escape') \n",
    "    file_dict['data'] = data\n",
    "    return\n",
    "\n",
    "def plot_peak(peak_dict,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    if not ('data' in peak_dict): \n",
    "        load_data_to_file_dict(peak_dict)\n",
    "    time_start = peak_dict['time_start']\n",
    "    time_end = peak_dict['time_end']\n",
    "    if time_end == 0 : time_end = peak_dict['data'].Time.iat[-1]\n",
    "    # \n",
    "    filtered_data = peak_dict['data'].query(f'Time > {time_start} and Time < {time_end}')\n",
    "    #\n",
    "    if xaxis not in peak_dict['data']:\n",
    "        print(\"ERROR: Invalid value for xaxis argument\")\n",
    "        return\n",
    "    elif xaxis == 'Time' :\n",
    "        plt.xlabel('Time [s]')\n",
    "    elif xaxis == 'Ts' :\n",
    "        plt.xlabel('Ts [C]')\n",
    "    elif xaxis == 'Tr' :\n",
    "        plt.xlabel('Tr [C]')\n",
    "    plt.plot(filtered_data[xaxis],filtered_data['Heat-Flow'])\n",
    "    plt.ylabel('Heat Flow [W/g]')\n",
    "    plt.show()\n",
    "\n",
    "def plot_peak_list(peak_list,xaxis='Time',key='',value=['']):\n",
    "    \"\"\"\n",
    "    Given a list of dictionary files, plot temperature vs. time for each file into the same plot.\n",
    "    If key/value are specified, only plot the files for which the key has the specified value.\n",
    "\n",
    "    Input variables:\n",
    "        file_list : a list of dictionary files, each with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "        key: a string with the name of the key to shortlist the files\n",
    "        value: the value of the key used to select the shortlist of files\n",
    "    \n",
    "    Action: \n",
    "        Plot temperature vs. time for the selected files  \n",
    "    \"\"\"\n",
    "    if value == '' or key == '':\n",
    "        peak_shortlist = peak_list\n",
    "    else :\n",
    "        peak_shortlist = [f for f in peak_list if f[key] in value ]\n",
    "    #\n",
    "    fig, ax = plt.subplots()\n",
    "    if xaxis == 'Time' :\n",
    "        plt.xlabel('Time [s]')\n",
    "    elif xaxis == 'Ts' :\n",
    "        plt.xlabel('Ts [C]')\n",
    "    elif xaxis == 'Tr' :\n",
    "        plt.xlabel('Tr [C]')\n",
    "    else:\n",
    "        print(\"ERROR: unexpected xaxis label\")\n",
    "        return\n",
    "    #\n",
    "    for peak in peak_shortlist : \n",
    "        if not ('data' in peak): \n",
    "            load_data_to_file_dict(peak)\n",
    "        filtered_data = peak['data'].query(f\"Time > {peak['time_start']} and Time < {peak['time_end']}\")\n",
    "        plt.plot(filtered_data[xaxis],filtered_data['Heat-Flow'],label=peak['label'])\n",
    "    plt.ylabel('Heat-Flow [W/g]')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(peak_dict,verbose=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not ('data' in peak_dict): \n",
    "        load_data_to_file_dict(peak_dict)\n",
    "    time_start = peak_dict['time_start']\n",
    "    time_end = peak_dict['time_end']\n",
    "    if time_end == 0 : time_end = peak_dict['data'].Time.iat[-1]\n",
    "    # \n",
    "    peak_dict['filtered_data'] = peak_dict['data'].query(f'Time > {time_start} and Time < {time_end}').copy()\n",
    "\n",
    "def line_of_tuple(x,params):\n",
    "    return params[0]*(x-params[1]) + params[2]\n",
    "\n",
    "def intersection_of_lines(params1,params2):\n",
    "    \"\"\" \n",
    "    Given the equations of two lines (y(x) = params[2] + params[0]*(x-params[1])) \n",
    "    find the intersection point: \n",
    "        y01 + slope1*(x01 - x) = y02 + slope2*(x02 - x) \n",
    "        (slope2 - slope1) * x = (y02 - y01) + (slope2*x02-slope1*x01)\n",
    "        x = ((y02 - y01) + (slope2*x02-slope1*x01)) / (slope2 - slope1) \n",
    "    \"\"\"\n",
    "    if params1[0] == params2[0] :\n",
    "        raise ValueError(\"ERROR: the two lines are parallel, no (unique) intersection\")\n",
    "    x = (params2[2] - params1[2] - params2[0]*params2[1] + params1[0]*params1[1])/(params1[0]-params2[0])\n",
    "    y = line_of_tuple(x,params1)\n",
    "    return x,y\n",
    "\n",
    "def calc_baseline(peak_dict,xaxis='Time',verbose=False):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    filter_data(peak_dict)\n",
    "    filtered_data = peak_dict['filtered_data']\n",
    "    filtered_data['dHF_dx'] = np.gradient(filtered_data['Heat-Flow'], filtered_data[xaxis])\n",
    "    # \n",
    "    if 'line' in peak_dict['baseline_type'] : \n",
    "        xi = filtered_data[xaxis].iloc[0]\n",
    "        yi = filtered_data['Heat-Flow'].iloc[0]\n",
    "        xf = filtered_data[xaxis].iloc[-1]\n",
    "        yf = filtered_data['Heat-Flow'].iloc[-1]\n",
    "        if 'horizontal' in peak_dict['baseline_type'] :\n",
    "            slope = 0.\n",
    "        else :\n",
    "            slope = (yf-yi)/(xf-xi)\n",
    "        if 'right' in peak_dict['baseline_type'] :\n",
    "            peak_dict['baseline-left'] = (slope,xf,yf)\n",
    "            peak_dict['baseline-right'] = (slope,xf,yf)\n",
    "            filtered_data['baseline'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right'])\n",
    "        else :\n",
    "            peak_dict['baseline-left'] = (slope,xi,yi)\n",
    "            peak_dict['baseline-right'] = (slope,xi,yi)\n",
    "            filtered_data['baseline'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left'])\n",
    "    elif 'integral' in peak_dict['baseline_type'] : \n",
    "        xi = filtered_data[xaxis].iloc[0]\n",
    "        yi = filtered_data['Heat-Flow'].iloc[0]\n",
    "        if 'horizontal' in peak_dict['baseline_type'] :\n",
    "            dydxi = 0\n",
    "        else :\n",
    "            dydxi = filtered_data['dHF_dx'].iloc[0]\n",
    "        peak_dict['baseline-left'] = (dydxi,xi,yi)\n",
    "        #\n",
    "        xf = filtered_data[xaxis].iloc[-1]\n",
    "        yf = filtered_data['Heat-Flow'].iloc[-1]\n",
    "        if 'horizontal' in peak_dict['baseline_type'] :\n",
    "            dydxf = 0\n",
    "        else :\n",
    "            dydxf = filtered_data['dHF_dx'].iloc[-1]\n",
    "        peak_dict['baseline-right'] = (dydxf,xf,yf)\n",
    "        filtered_data['baseline-right'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right'])\n",
    "        filtered_data['baseline-left'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left'])\n",
    "        baseline = np.ones(filtered_data['Heat-Flow'].shape)*(yi+yf)*0.5\n",
    "        for i in range(10): \n",
    "            gamma = cumulative_trapezoid(filtered_data['Heat-Flow']-baseline,filtered_data[xaxis],initial=0)/simps(filtered_data['Heat-Flow']-baseline,filtered_data[xaxis])\n",
    "            baseline = (1-gamma)*filtered_data['baseline-left'] + gamma*filtered_data['baseline-right']\n",
    "        filtered_data['baseline'] = baseline\n",
    "    filtered_data['Heat-Flow-Clean'] = filtered_data['Heat-Flow'] - filtered_data['baseline']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_peak(peak_dict,verbose=False,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    calc_baseline(peak_dict,xaxis)\n",
    "    #\n",
    "    filtered_data = peak_dict['filtered_data']\n",
    "    # Compute the integral\n",
    "    peak_integral = simps(filtered_data['Heat-Flow-Clean'],filtered_data['Time'])\n",
    "    peak_dict['integral'] = peak_integral\n",
    "    if verbose : print(f'The peak integral is {peak_integral:8.6f}')\n",
    "    # Peak position\n",
    "    if peak_integral < 0 : \n",
    "        index_peak = np.argmin(filtered_data['Heat-Flow'])\n",
    "    else : \n",
    "        index_peak = np.argmax(filtered_data['Heat-Flow'])\n",
    "    x_peak = filtered_data[xaxis].iloc[index_peak]\n",
    "    y_peak = filtered_data['Heat-Flow'].iloc[index_peak]\n",
    "    peak_dict['peak'] = (x_peak,y_peak)\n",
    "    # Inflaction points (max and min of first derivative are zeros of second derivative)\n",
    "    left_data = filtered_data.iloc[:index_peak]\n",
    "    if peak_integral < 0 :\n",
    "        index_inflection_left = np.argmin(left_data['dHF_dx'])\n",
    "    else : \n",
    "        index_inflection_left = np.argmax(left_data['dHF_dx'])\n",
    "    x_infl_left = left_data[xaxis].iloc[index_inflection_left]\n",
    "    y_infl_left = left_data['Heat-Flow'].iloc[index_inflection_left]\n",
    "    slope_infl_left = left_data['dHF_dx'].iloc[index_inflection_left]\n",
    "    peak_dict['inflection1'] = (slope_infl_left, x_infl_left, y_infl_left)\n",
    "    right_data = filtered_data.iloc[index_peak+1:]\n",
    "    if peak_integral < 0 :\n",
    "        index_inflection_right = np.argmax(right_data['dHF_dx'])\n",
    "    else : \n",
    "        index_inflection_right = np.argmin(right_data['dHF_dx'])\n",
    "    x_infl_right = right_data[xaxis].iloc[index_inflection_right]\n",
    "    y_infl_right = right_data['Heat-Flow'].iloc[index_inflection_right]\n",
    "    slope_infl_right = right_data['dHF_dx'].iloc[index_inflection_right]\n",
    "    peak_dict['inflection2'] = (slope_infl_right, x_infl_right, y_infl_right)\n",
    "    # Onset\n",
    "    onset_x, onset_y = intersection_of_lines(peak_dict['inflection1'],peak_dict['baseline-left'])\n",
    "    peak_dict['onset'] = (onset_x,onset_y)\n",
    "    # Endset\n",
    "    endset_x, endset_y = intersection_of_lines(peak_dict['inflection2'],peak_dict['baseline-right'])\n",
    "    peak_dict['endset'] = (endset_x,endset_y)\n",
    "    # Extrapolated Peak\n",
    "    extrapolated_peak_x, extrapolated_peak_y = intersection_of_lines(peak_dict['inflection1'],peak_dict['inflection2'])\n",
    "    peak_dict['extrapolated_peak'] = (extrapolated_peak_x,extrapolated_peak_y)\n",
    "    if verbose :\n",
    "        plot_analysis(peak_dict,xaxis)\n",
    "\n",
    "def plot_analysis(peak_dict,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    filtered_data = peak_dict['filtered_data']\n",
    "    plt.plot(filtered_data[xaxis],filtered_data['Heat-Flow'])\n",
    "    plt.plot(filtered_data[xaxis],line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left']))\n",
    "    plt.plot(filtered_data[xaxis],line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right']))\n",
    "    plt.plot(filtered_data[xaxis],filtered_data['baseline'])\n",
    "    plt.scatter(peak_dict['extrapolated_peak'][0],peak_dict['extrapolated_peak'][1],label=f\"Extrapolated Peak = {peak_dict['extrapolated_peak'][0]:6.2f} s\")\n",
    "    plt.scatter(peak_dict['onset'][0],peak_dict['onset'][1],label=f\"Onset = {peak_dict['onset'][0]:6.2f} s\")\n",
    "    plt.scatter(peak_dict['endset'][0],peak_dict['endset'][1],label=f\"Endset = {peak_dict['endset'][0]:6.2f} s\")\n",
    "    inflaction_points = [[peak_dict['inflection1'][1],peak_dict['inflection2'][1]],[peak_dict['inflection1'][2],peak_dict['inflection2'][2]]]\n",
    "    plt.scatter(inflaction_points[0],inflaction_points[1],marker='x',label='Inflections')\n",
    "    x_tmp = np.linspace(peak_dict['onset'][0],peak_dict['extrapolated_peak'][0],10)\n",
    "    plt.plot(x_tmp,line_of_tuple(x_tmp,peak_dict['inflection1']),':',color='grey')\n",
    "    x_tmp = np.linspace(peak_dict['extrapolated_peak'][0],peak_dict['endset'][0],10)\n",
    "    plt.plot(x_tmp,line_of_tuple(x_tmp,peak_dict['inflection2']),':',color='grey')\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Systems {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following module needs to be installed on Colab. We won't need it too much for this analysis, but they offer a lot of nice features for chemistry programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install and load RDKit { display-mode: \"form\" }\n",
    "!pip install rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "!pip install cirpy\n",
    "import cirpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular we can use them to draw the molecules in our experiments. While for some molecules you can just write their names and RDKit will plot them, for most molecules you will need to provide their SMILES or their CAS numbers. Luckily, CIRpy can usually find SMILES for you, if you type the common name correctly or if you know the CAS number. \n",
    "\n",
    "These are the SMILES for the molecules in your DSC experiments:\n",
    "* paracetamol: 'CC(=O)Nc1ccc(O)cc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Choose the molecule to draw { display-mode: \"form\" }\n",
    "input = 'paracetamol' # @param {type:\"string\"}\n",
    "input_type = 'name' # @param [\"smiles\", \"name\", \"cas\"] {allow-input: true}\n",
    "if input_type != 'smiles' :\n",
    "    smiles=cirpy.resolve( input, 'smiles')\n",
    "else:\n",
    "    smiles=input\n",
    "img = Draw.MolToImage( Chem.MolFromSmiles(smiles), size=(300, 300) )\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the Google Drive and access an example of a dataset from a kinetics experiment. You can use the same set that I am using by downloading it from Canvas, [here](). Or you can use your own files. I am assuming the file in question will be located in a `Kinetics_Data/` subfolder in your `Colab Notebook/` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set Local Path { display-mode: \"form\" }\n",
    "# The following needs to be the path of the folder with all your collected data in .csv format\n",
    "local_path=\"Colab Notebooks/DSC_Data/\" # @param {type:\"string\"}\n",
    "path = base_path+local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './DSC_Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to streamline the fitting of the data, we will be storing the file that corresponds to each experiment into a Python dictionary (`dict`), together with all the relevant information of that experiment and the parameters that we need for the fit. You can use the same statement in the following, but make sure to change the file name from 'indium.txt' (the one that I am using) to the one you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indium_melting = {'path':path, 'name':'indium.txt', 'label':'In melting', 'time_start': 300, 'time_end': 350, 'baseline_width': 61}\n",
    "indium_freezing = {'path':path, 'name':'indium.txt', 'label':'In freezing', 'time_start': 0, 'time_end': 0, 'baseline_width': 61}\n",
    "\n",
    "indium_peaks = [indium_melting, indium_freezing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peak_list(indium_peaks,'Ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_file_dict(indium_melting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should always check that the loaded data looks ok, say by checking the number of columns and rows and, maybe, plotting the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indium_melting['data'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the Analysis Parameters {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find a reasonable time interval around the melting peak { display-mode: \"form\" }\n",
    "time_start = 300 # @param {type:\"number\"}\n",
    "time_end = 350 # @param {type:\"number\"}\n",
    "baseline_type = 'line' # @param ['line','horizontal-line','integral','horizontal-integral'] {allow-input: true}\n",
    "indium_melting['time_start'] = time_start\n",
    "indium_melting['time_end'] = time_end\n",
    "indium_melting['baseline_type'] = baseline_type\n",
    "calc_baseline(indium_melting,verbose=True,xaxis='Ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = analyze_peak(indium_melting,xaxis='Ts',verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find a reasonable time interval around the melting peak { display-mode: \"form\" }\n",
    "time_start = 580 # @param {type:\"number\"}\n",
    "time_end = 620 # @param {type:\"number\"}\n",
    "baseline_type = 'integral' # @param ['line','horizontal-line','integral','horizontal-integral'] {allow-input: true}\n",
    "indium_freezing['time_start'] = time_start\n",
    "indium_freezing['time_end'] = time_end\n",
    "indium_freezing['baseline_type'] = baseline_type\n",
    "calc_baseline(indium_freezing,verbose=True,xaxis='Ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_peak(indium_freezing,xaxis='Ts',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para1 = {'path':path, 'name':'para1.txt', 'label':'In melting', 'time_start': 0, 'time_end': 0}\n",
    "para2 = {'path':path, 'name':'para2.txt', 'label':'In melting', 'time_start': 0, 'time_end': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find a reasonable time interval around the melting peak { display-mode: \"form\" }\n",
    "time_start = 320 # @param {type:\"number\"}\n",
    "time_end = 400 # @param {type:\"number\"}\n",
    "baseline_type = 'integral' # @param ['line','horizontal-line','integral','horizontal-integral'] {allow-input: true}\n",
    "para1['time_start'] = time_start\n",
    "para1['time_end'] = time_end\n",
    "para1['baseline_type'] = baseline_type\n",
    "calc_baseline(para1,verbose=True,xaxis='Ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_peak(para1,xaxis='Ts',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para2_1 = {'path':path, 'name':'para2.txt', 'label':'In melting', 'time_start': 60, 'time_end': 200, 'baseline_type' : 'integral'}\n",
    "para2_2 = {'path':path, 'name':'para2.txt', 'label':'In melting', 'time_start': 300, 'time_end': 380, 'baseline_type' : 'integral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_baseline(para2_1,xaxis='Ts',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_peak(para2_1,xaxis='Ts',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_peak(para2_2,verbose=True,xaxis='Ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotton = {'path':path, 'name':'cotton.txt', 'label':'In melting', 'time_start':600, 'time_end': 850, 'baseline_type': 'integral'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_peak(cotton,verbose=True,xaxis='Ts')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
