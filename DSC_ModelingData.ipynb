{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr Oliviero Andreussi, olivieroandreuss@boisestate.edu\n",
    "\n",
    "Boise State University, Department of Chemistry and Biochemistry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and Data Analysis for the Differential Scanning Calorimetry Experiment {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Setup {-}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let us import the main modules that we will need for this lecture. You may see some new modules in the list below, we will add more details in the right sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Notebook Setup { display-mode: \"form\" }\n",
    "# Import the main modules used in this worksheet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import medfilt\n",
    "from scipy.integrate import simps, cumulative_trapezoid\n",
    "# Load the google drive with your files \n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "# The following needs to be the path of the folder with all your datafile in .csv format\n",
    "base_path = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions to load the data { display-mode: \"form\" }\n",
    "def load_data_to_file_dict(file_dict):\n",
    "    \"\"\"\n",
    "    Load a DSC .txt file. \n",
    "    The format of the file should have two rows of headers, one extra line of text at the end, and five columns of data\n",
    "    The columns are: index, time, heat flow, temperature of sample, temperature of reference\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Add to file_dict a Pandas DataFrame with four columns: time (in seconds), heat flow (in W/g), \n",
    "        temperature of sample (in C), and temperature of reference (in C)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_dict['path']+file_dict['name'],skiprows=2,skipfooter=1,names=['Time','Heat-Flow','Ts','Tr'],sep=' +',index_col=0,engine='python',encoding='unicode_escape') \n",
    "    file_dict['data'] = data\n",
    "    return\n",
    "\n",
    "def filter_data(peak_dict,verbose=False):\n",
    "    \"\"\"\n",
    "    Given a file dictionary that contains two values for the time interval to analyze\n",
    "    create a 'filtered_data' component with only the data in the specified time range\n",
    "\n",
    "    By default, time_end = 0 corresponds to the end of the file\n",
    "\n",
    "    Action:\n",
    "        If not present, load the data from the file into peak_dict['data']\n",
    "        Add peak_dict['filtered_data'] with only the part of the experiment within time_start and time_end\n",
    "    \"\"\"\n",
    "    if not ('data' in peak_dict): \n",
    "        load_data_to_file_dict(peak_dict)\n",
    "    time_start = peak_dict['time_start']\n",
    "    time_end = peak_dict['time_end']\n",
    "    if time_end == 0 : time_end = peak_dict['data'].Time.iat[-1]\n",
    "    # \n",
    "    peak_dict['filtered_data'] = peak_dict['data'].query(f'Time > {time_start} and Time < {time_end}').copy()\n",
    "\n",
    "def plot_peak(peak_dict,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    if not ('data' in peak_dict): \n",
    "        load_data_to_file_dict(peak_dict)\n",
    "    time_start = peak_dict['time_start']\n",
    "    time_end = peak_dict['time_end']\n",
    "    if time_end == 0 : time_end = peak_dict['data'].Time.iat[-1]\n",
    "    # \n",
    "    filtered_data = peak_dict['data'].query(f'Time > {time_start} and Time < {time_end}')\n",
    "    #\n",
    "    if xaxis not in peak_dict['data']:\n",
    "        print(\"ERROR: Invalid value for xaxis argument\")\n",
    "        return\n",
    "    elif xaxis == 'Time' :\n",
    "        plt.xlabel('Time [s]')\n",
    "    elif xaxis == 'Ts' :\n",
    "        plt.xlabel('Ts [C]')\n",
    "    elif xaxis == 'Tr' :\n",
    "        plt.xlabel('Tr [C]')\n",
    "    plt.plot(filtered_data[xaxis],filtered_data['Heat-Flow'])\n",
    "    plt.ylabel('Heat Flow [W/g]')\n",
    "    plt.show()\n",
    "\n",
    "def plot_peak_list(peak_list,xaxis='Time',key='',value=['']):\n",
    "    \"\"\"\n",
    "    Given a list of dictionary files, plot temperature vs. time for each file into the same plot.\n",
    "    If key/value are specified, only plot the files for which the key has the specified value.\n",
    "\n",
    "    Input variables:\n",
    "        file_list : a list of dictionary files, each with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "        key: a string with the name of the key to shortlist the files\n",
    "        value: the value of the key used to select the shortlist of files\n",
    "    \n",
    "    Action: \n",
    "        Plot temperature vs. time for the selected files  \n",
    "    \"\"\"\n",
    "    if value == '' or key == '':\n",
    "        peak_shortlist = peak_list\n",
    "    else :\n",
    "        peak_shortlist = [f for f in peak_list if f[key] in value ]\n",
    "    #\n",
    "    fig, ax = plt.subplots()\n",
    "    if xaxis == 'Time' :\n",
    "        plt.xlabel('Time [s]')\n",
    "    elif xaxis == 'Ts' :\n",
    "        plt.xlabel('Ts [C]')\n",
    "    elif xaxis == 'Tr' :\n",
    "        plt.xlabel('Tr [C]')\n",
    "    else:\n",
    "        print(\"ERROR: unexpected xaxis label\")\n",
    "        return\n",
    "    #\n",
    "    for peak in peak_shortlist : \n",
    "        filter_data(peak)\n",
    "        plt.plot(peak['filtered_data'][xaxis],peak['filtered_data']['Heat-Flow'],label=peak['label'])\n",
    "    plt.ylabel('Heat-Flow [W/g]')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Utilities to analyze the data { display-mode: \"form\" }\n",
    "def line_of_tuple(x,params):\n",
    "    \"\"\" \n",
    "    given a list of 3 parameters compute a line according to \n",
    "        y(x) = params[2] + params[0]*(x-params[1])\n",
    "    \"\"\"\n",
    "    return params[0]*(x-params[1]) + params[2]\n",
    "\n",
    "def intersection_of_lines(params1,params2):\n",
    "    \"\"\" \n",
    "    Given the equations of two lines (y(x) = params[2] + params[0]*(x-params[1])) \n",
    "    find the intersection point: \n",
    "        y01 + slope1*(x01 - x) = y02 + slope2*(x02 - x) \n",
    "        (slope2 - slope1) * x = (y02 - y01) + (slope2*x02-slope1*x01)\n",
    "        x = ((y02 - y01) + (slope2*x02-slope1*x01)) / (slope2 - slope1) \n",
    "    \"\"\"\n",
    "    if params1[0] == params2[0] :\n",
    "        raise ValueError(\"ERROR: the two lines are parallel, no (unique) intersection\")\n",
    "    x = (params2[2] - params1[2] - params2[0]*params2[1] + params1[0]*params1[1])/(params1[0]-params2[0])\n",
    "    y = line_of_tuple(x,params1)\n",
    "    return x,y\n",
    "\n",
    "def calc_baseline(peak_dict,xaxis='Time',verbose=False):\n",
    "    \"\"\" \n",
    "    Compute a baseline for the data according to a few alternative options\n",
    "\n",
    "    Baseline types, specified in the peak_dict['baseline_type'] component, can be:\n",
    "        line-right = a line tangent to the right extreme of the data\n",
    "        line-left = a line tangent to the left extreme of the data\n",
    "        line-horizontal-right = a flat line passing throught the right extreme\n",
    "        line-horizontal-left = a flat line passing throught the left extreme\n",
    "        integral = a smooth combination of left and right tangents \n",
    "        integral-horizontal = a smooth combination of left and right flat lines\n",
    "\n",
    "    Action: \n",
    "        Compute left, right, and full baseline\n",
    "        Add them to the peak_dict['filtered_data'] component\n",
    "        Compute peak_dict['Heat-Flow-Clean'], the heat-flow minus the full baseline \n",
    "    \"\"\"\n",
    "    filter_data(peak_dict)\n",
    "    filtered_data = peak_dict['filtered_data']\n",
    "    filtered_data['dHF_dx'] = np.gradient(filtered_data['Heat-Flow'], filtered_data[xaxis])\n",
    "    # \n",
    "    if 'line' in peak_dict['baseline_type'] : \n",
    "        xi = filtered_data[xaxis].iloc[0]\n",
    "        yi = filtered_data['Heat-Flow'].iloc[0]\n",
    "        xf = filtered_data[xaxis].iloc[-1]\n",
    "        yf = filtered_data['Heat-Flow'].iloc[-1]\n",
    "        if 'horizontal' in peak_dict['baseline_type'] :\n",
    "            slope = 0.\n",
    "        else :\n",
    "            slope = (yf-yi)/(xf-xi)\n",
    "        if 'right' in peak_dict['baseline_type'] :\n",
    "            peak_dict['baseline-left'] = (slope,xf,yf)\n",
    "            peak_dict['baseline-right'] = (slope,xf,yf)\n",
    "            filtered_data['baseline'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right'])\n",
    "        else :\n",
    "            peak_dict['baseline-left'] = (slope,xi,yi)\n",
    "            peak_dict['baseline-right'] = (slope,xi,yi)\n",
    "            filtered_data['baseline'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left'])\n",
    "    elif 'integral' in peak_dict['baseline_type'] : \n",
    "        xi = filtered_data[xaxis].iloc[0]\n",
    "        yi = filtered_data['Heat-Flow'].iloc[0]\n",
    "        if 'horizontal' in peak_dict['baseline_type'] :\n",
    "            dydxi = 0\n",
    "        else :\n",
    "            dydxi = filtered_data['dHF_dx'].iloc[0]\n",
    "        peak_dict['baseline-left'] = (dydxi,xi,yi)\n",
    "        #\n",
    "        xf = filtered_data[xaxis].iloc[-1]\n",
    "        yf = filtered_data['Heat-Flow'].iloc[-1]\n",
    "        if 'horizontal' in peak_dict['baseline_type'] :\n",
    "            dydxf = 0\n",
    "        else :\n",
    "            dydxf = filtered_data['dHF_dx'].iloc[-1]\n",
    "        peak_dict['baseline-right'] = (dydxf,xf,yf)\n",
    "        filtered_data['baseline-right'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right'])\n",
    "        filtered_data['baseline-left'] = line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left'])\n",
    "        baseline = np.ones(filtered_data['Heat-Flow'].shape)*(yi+yf)*0.5\n",
    "        for i in range(10): \n",
    "            gamma = cumulative_trapezoid(filtered_data['Heat-Flow']-baseline,filtered_data[xaxis],initial=0)/simps(filtered_data['Heat-Flow']-baseline,filtered_data[xaxis])\n",
    "            baseline = (1-gamma)*filtered_data['baseline-left'] + gamma*filtered_data['baseline-right']\n",
    "        filtered_data['baseline'] = baseline\n",
    "    filtered_data['Heat-Flow-Clean'] = filtered_data['Heat-Flow'] - filtered_data['baseline']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Main functions to analyze the data { display-mode: \"form\" }\n",
    "def analyze_peak(peak_dict,verbose=False,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    calc_baseline(peak_dict,xaxis)\n",
    "    #\n",
    "    filtered_data = peak_dict['filtered_data']\n",
    "    # Compute the integral\n",
    "    peak_integral = simps(filtered_data['Heat-Flow-Clean'],filtered_data['Time'])\n",
    "    peak_dict['integral'] = peak_integral\n",
    "    peak_integral_xaxis = simps(filtered_data['Heat-Flow-Clean'],filtered_data[xaxis])\n",
    "    if verbose : print(f'The peak integral is {peak_integral:8.6f}')\n",
    "    # Peak position\n",
    "    if peak_integral < 0 : \n",
    "        index_peak = np.argmin(filtered_data['Heat-Flow'])\n",
    "    else : \n",
    "        index_peak = np.argmax(filtered_data['Heat-Flow'])\n",
    "    x_peak = filtered_data[xaxis].iloc[index_peak]\n",
    "    y_peak = filtered_data['Heat-Flow'].iloc[index_peak]\n",
    "    peak_dict['peak'] = (x_peak,y_peak)\n",
    "    # Inflaction points (max and min of first derivative are zeros of second derivative)\n",
    "    left_data = filtered_data.iloc[:index_peak]\n",
    "    if peak_integral_xaxis < 0 :\n",
    "        index_inflection_left = np.argmin(left_data['dHF_dx'])\n",
    "    else : \n",
    "        index_inflection_left = np.argmax(left_data['dHF_dx'])\n",
    "    x_infl_left = left_data[xaxis].iloc[index_inflection_left]\n",
    "    y_infl_left = left_data['Heat-Flow'].iloc[index_inflection_left]\n",
    "    slope_infl_left = left_data['dHF_dx'].iloc[index_inflection_left]\n",
    "    peak_dict['inflection1'] = (slope_infl_left, x_infl_left, y_infl_left)\n",
    "    right_data = filtered_data.iloc[index_peak+1:]\n",
    "    if peak_integral_xaxis < 0 :\n",
    "        index_inflection_right = np.argmax(right_data['dHF_dx'])\n",
    "    else : \n",
    "        index_inflection_right = np.argmin(right_data['dHF_dx'])\n",
    "    x_infl_right = right_data[xaxis].iloc[index_inflection_right]\n",
    "    y_infl_right = right_data['Heat-Flow'].iloc[index_inflection_right]\n",
    "    slope_infl_right = right_data['dHF_dx'].iloc[index_inflection_right]\n",
    "    peak_dict['inflection2'] = (slope_infl_right, x_infl_right, y_infl_right)\n",
    "    # Onset\n",
    "    onset_x, onset_y = intersection_of_lines(peak_dict['inflection1'],peak_dict['baseline-left'])\n",
    "    peak_dict['onset'] = (onset_x,onset_y)\n",
    "    # Endset\n",
    "    endset_x, endset_y = intersection_of_lines(peak_dict['inflection2'],peak_dict['baseline-right'])\n",
    "    peak_dict['endset'] = (endset_x,endset_y)\n",
    "    # Extrapolated Peak\n",
    "    extrapolated_peak_x, extrapolated_peak_y = intersection_of_lines(peak_dict['inflection1'],peak_dict['inflection2'])\n",
    "    peak_dict['extrapolated_peak'] = (extrapolated_peak_x,extrapolated_peak_y)\n",
    "    if verbose :\n",
    "        plot_analysis(peak_dict,xaxis)\n",
    "\n",
    "def plot_analysis(peak_dict,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    if xaxis == 'Time' : \n",
    "        units = ' s'\n",
    "    elif xaxis == 'Ts' or xaxis == 'Tr' :\n",
    "        units = u'\\N{DEGREE SIGN} C'\n",
    "    filtered_data = peak_dict['filtered_data']\n",
    "    plt.plot(filtered_data[xaxis],filtered_data['Heat-Flow'])\n",
    "    plt.plot(filtered_data[xaxis],line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left']))\n",
    "    plt.plot(filtered_data[xaxis],line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right']))\n",
    "    plt.plot(filtered_data[xaxis],filtered_data['baseline'])\n",
    "    plt.scatter(peak_dict['extrapolated_peak'][0],peak_dict['extrapolated_peak'][1],label=f\"Extrapolated Peak = {peak_dict['extrapolated_peak'][0]:6.2f}\"+units)\n",
    "    plt.scatter(peak_dict['onset'][0],peak_dict['onset'][1],label=f\"Onset = {peak_dict['onset'][0]:6.2f}\"+units)\n",
    "    plt.scatter(peak_dict['endset'][0],peak_dict['endset'][1],label=f\"Endset = {peak_dict['endset'][0]:6.2f}\"+units)\n",
    "    inflaction_points = [[peak_dict['inflection1'][1],peak_dict['inflection2'][1]],[peak_dict['inflection1'][2],peak_dict['inflection2'][2]]]\n",
    "    plt.scatter(inflaction_points[0],inflaction_points[1],marker='x',label='Inflections')\n",
    "    x_tmp = np.linspace(peak_dict['onset'][0],peak_dict['extrapolated_peak'][0],10)\n",
    "    plt.plot(x_tmp,line_of_tuple(x_tmp,peak_dict['inflection1']),':',color='grey')\n",
    "    x_tmp = np.linspace(peak_dict['extrapolated_peak'][0],peak_dict['endset'][0],10)\n",
    "    plt.plot(x_tmp,line_of_tuple(x_tmp,peak_dict['inflection2']),':',color='grey')\n",
    "    plt.legend()\n",
    "\n",
    "def plot_analysis_list(peak_list,xaxis='Time'):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    if xaxis == 'Time' : \n",
    "        units = ' s'\n",
    "    elif xaxis == 'Ts' or xaxis == 'Tr' :\n",
    "        units = u'\\N{DEGREE SIGN} C'\n",
    "    for peak_dict in peak_list: \n",
    "        filtered_data = peak_dict['filtered_data']\n",
    "        plt.plot(filtered_data[xaxis],filtered_data['Heat-Flow'])\n",
    "        plt.plot(filtered_data[xaxis],line_of_tuple(filtered_data[xaxis],peak_dict['baseline-left']))\n",
    "        plt.plot(filtered_data[xaxis],line_of_tuple(filtered_data[xaxis],peak_dict['baseline-right']))\n",
    "        plt.plot(filtered_data[xaxis],filtered_data['baseline'])\n",
    "        plt.scatter(peak_dict['extrapolated_peak'][0],peak_dict['extrapolated_peak'][1],label=f\"Extrapolated Peak = {peak_dict['extrapolated_peak'][0]:6.2f}\"+units)\n",
    "        plt.scatter(peak_dict['onset'][0],peak_dict['onset'][1],label=f\"Onset = {peak_dict['onset'][0]:6.2f}\"+units)\n",
    "        plt.scatter(peak_dict['endset'][0],peak_dict['endset'][1],label=f\"Endset = {peak_dict['endset'][0]:6.2f}\"+units)\n",
    "        inflaction_points = [[peak_dict['inflection1'][1],peak_dict['inflection2'][1]],[peak_dict['inflection1'][2],peak_dict['inflection2'][2]]]\n",
    "        plt.scatter(inflaction_points[0],inflaction_points[1],marker='x',label='Inflections')\n",
    "        x_tmp = np.linspace(peak_dict['onset'][0],peak_dict['extrapolated_peak'][0],10)\n",
    "        plt.plot(x_tmp,line_of_tuple(x_tmp,peak_dict['inflection1']),':',color='grey')\n",
    "        x_tmp = np.linspace(peak_dict['extrapolated_peak'][0],peak_dict['endset'][0],10)\n",
    "        plt.plot(x_tmp,line_of_tuple(x_tmp,peak_dict['inflection2']),':',color='grey')\n",
    "        plt.legend()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Systems {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following module needs to be installed on Colab. We won't need it too much for this analysis, but they offer a lot of nice features for chemistry programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install and load RDKit { display-mode: \"form\" }\n",
    "!pip install rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "!pip install cirpy\n",
    "import cirpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular we can use them to draw the molecules in our experiments. While for some molecules you can just write their names and RDKit will plot them, for most molecules you will need to provide their SMILES or their CAS numbers. Luckily, CIRpy can usually find SMILES for you, if you type the common name correctly or if you know the CAS number. \n",
    "\n",
    "These are the SMILES for the molecules in your DSC experiments:\n",
    "* paracetamol: 'CC(=O)Nc1ccc(O)cc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Choose the molecule to draw { display-mode: \"form\" }\n",
    "input = 'paracetamol' # @param {type:\"string\"}\n",
    "input_type = 'name' # @param [\"smiles\", \"name\", \"cas\"] {allow-input: true}\n",
    "if input_type != 'smiles' :\n",
    "    smiles=cirpy.resolve( input, 'smiles')\n",
    "else:\n",
    "    smiles=input\n",
    "img = Draw.MolToImage( Chem.MolFromSmiles(smiles), size=(300, 300) )\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the Google Drive and access an example of a dataset from a kinetics experiment. You can use the same set that I am using by downloading it from Canvas, [here](). Or you can use your own files. I am assuming the file in question will be located in a `Kinetics_Data/` subfolder in your `Colab Notebook/` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set Local Path { display-mode: \"form\" }\n",
    "# The following needs to be the path of the folder with all your collected data in .csv format\n",
    "local_path=\"Colab Notebooks/DSC_Data/\" # @param {type:\"string\"}\n",
    "path = base_path+local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './DSC_Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to streamline the fitting of the data, we will be storing the information that corresponds to each peak of a DSC experiment into a Python dictionary (`dict`), together with all the relevant information of that experiment and the parameters that we need for the fit. NOTE: for these experiments, since we need to fit and get information from different peaks or steps in the DSC curves, we will create a separate dictionary for each feature we want to analyze. You can use the same statement in the following, but make sure to change the file name from 'indium.txt' (the one that I am using) to the one you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indium_melting = {'path':path, 'name':'indium.txt', 'label':'In Melting', 'time_start': 0, 'time_end': 0, 'baseline_type': 'line'}\n",
    "indium_freezing = {'path':path, 'name':'indium.txt', 'label':'In Freezing', 'time_start': 0, 'time_end': 0, 'baseline_type': 'line'}\n",
    "\n",
    "indium_peaks = [indium_melting, indium_freezing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the data into each dictionary as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_file_dict(indium_melting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a new component of the dictionary named 'data', which will contain a DataFrame generated from the DSC file specified in the dictionary. We should always check that the loaded data looks ok, say by checking the number of columns and rows and, maybe, plotting the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indium_melting['data'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indium_melting['data'].plot('Time','Ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we created a set of tools that allows you to load the data, filter them on the speficied time interval, and plot them in one step. For a single dictionary you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peak(indium_melting,'Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you want to plot multiple peaks in a single plot, you can use the `plot_peak_list([peak1, peak2])` instead, which expects a list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peak_list(indium_peaks,'Tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the Analysis Parameters {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find a reasonable time interval around the melting peak { display-mode: \"form\" }\n",
    "time_start = 100 # @param {type:\"number\"}\n",
    "time_end = 400 # @param {type:\"number\"}\n",
    "baseline_type = 'line' # @param ['line','horizontal-line','integral','horizontal-integral'] {allow-input: true}\n",
    "xaxis = 'Tr' # @param ['Time','Tr','Ts']\n",
    "indium_melting['time_start'] = time_start\n",
    "indium_melting['time_end'] = time_end\n",
    "indium_melting['baseline_type'] = baseline_type\n",
    "plot = analyze_peak(indium_melting,xaxis=xaxis,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find a reasonable time interval around the freezing peak { display-mode: \"form\" }\n",
    "time_start = 500 # @param {type:\"number\"}\n",
    "time_end = 700 # @param {type:\"number\"}\n",
    "baseline_type = 'line' # @param ['line','horizontal-line','integral','horizontal-integral'] {allow-input: true}\n",
    "xaxis = 'Tr' # @param ['Time','Tr','Ts']\n",
    "indium_freezing['time_start'] = time_start\n",
    "indium_freezing['time_end'] = time_end\n",
    "indium_freezing['baseline_type'] = baseline_type\n",
    "analyze_peak(indium_freezing,xaxis=xaxis,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE that the information that is printed on the graphs is also stored in the dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indium_melting['onset']) # this outputs the coordinates of the point\n",
    "print(indium_melting['extrapolated_peak']) # this outputs the coordinates of the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analysis_list(indium_peaks,xaxis='Tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Each of Your Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this analysis for each one of your curves. Make sure to take note of the times that affect your analysis the most, you will need them in your worksheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Find a reasonable time interval around the freezing peak { display-mode: \"form\" }\n",
    "filename = 'para1.txt' # @param {type:\"string\"}\n",
    "time_start = 350 # @param {type:\"number\"}\n",
    "time_end = 0 # @param {type:\"number\"}\n",
    "baseline_type = 'line' # @param ['line','horizontal-line','integral','horizontal-integral'] {allow-input: true}\n",
    "xaxis = 'Tr' # @param ['Time','Tr','Ts']\n",
    "check_type = 'analyze' # @param ['plot', 'analyze']\n",
    "newpeak = {'path':path, 'name':filename, 'label':'check', 'time_start': time_start, 'time_end': time_end, 'baseline_type': baseline_type}\n",
    "if check_type == 'plot':\n",
    "    plot_peak(newpeak,xaxis=xaxis)\n",
    "elif check_type == 'analyze':\n",
    "    analyze_peak(newpeak,xaxis=xaxis,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
