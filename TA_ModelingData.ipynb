{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr Oliviero Andreussi, olivieroandreuss@boisestate.edu\n",
    "\n",
    "Boise State University, Department of Chemistry and Biochemistry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and Data Analysis for the Transient Absorption Spectroscopy Experiment {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Setup {-}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let us import the main modules that we will need for this lecture. You may see some new modules in the list below, we will add more details in the right sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Notebook Setup { display-mode: \"form\" }\n",
    "# Import the main modules used in this worksheet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Load the google drive with your files \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# The following needs to be the path of the folder with all your datafile in .csv format\n",
    "base_path = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions to load the data { display-mode: \"form\" }\n",
    "def load_data_to_file_dict(file_dict):\n",
    "    \"\"\"\n",
    "    Load a Transient Absorption Spectroscopy .csv file. \n",
    "    The format of the file should have one row of header, semicolon as separator, and colon as decimal separator\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Add to file_dict a Pandas DataFrame with multiple columns: Laser Delay (in nanoseconds)\n",
    "        and one column for each TA run in units of mOD\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_dict['path']+file_dict['name'],sep=';',decimal=',') \n",
    "    file_dict['data'] = data\n",
    "    return\n",
    "\n",
    "def plot_file_dict(file_dict, yaxis = 'all'):\n",
    "    \"\"\" \n",
    "    Given a file dictionary, plot one of the transient absorption curves (or the average)\n",
    "    versus the laser delay\n",
    "    \"\"\"\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    if yaxis == 'all':\n",
    "        for column in file_dict['data'].columns:\n",
    "            if column == 'Laser Delay [ns]' : continue\n",
    "            plt.plot(file_dict['data']['Laser Delay [ns]'],file_dict['data'][column],label=column)\n",
    "    else : \n",
    "        if yaxis in file_dict['data'].columns:\n",
    "            plt.plot(file_dict['data']['Laser Delay [ns]'],file_dict['data'][yaxis],label=yaxis)\n",
    "        else:\n",
    "            print('ERROR: specified yaxis is not in the read data')\n",
    "    plt.ylabel('Transient Absorption [mOD]')\n",
    "    plt.xlabel('Laser Delay [ns]')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_file_list(file_list,yaxis = 'TA1 [mOD]'):\n",
    "    \"\"\"\n",
    "    Given a list of dictionary files, plot one of the transient absorption curves (or the average)\n",
    "    versus the laser delay for each of the files\n",
    "    \"\"\"\n",
    "    #\n",
    "    fig, ax = plt.subplots()\n",
    "    #\n",
    "    for file_dict in file_list : \n",
    "        (file_dict)\n",
    "        plt.plot(file_dict['data']['Laser Delay [ns]'],file_dict['data'][yaxis],label=file_dict['label'])\n",
    "    plt.ylabel('Transient Absorption [mOD]')\n",
    "    plt.xlabel('Laser Delay [ns]')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Utilities to analyze the data { display-mode: \"form\" }\n",
    "def exponential(t, a, tau, o):\n",
    "    \"\"\" \n",
    "    Function that returns an exponentially decaying function plus offset\n",
    "    f(t) = o + a*e^(-t/tau)\n",
    "\n",
    "    input variables\n",
    "    t: input value (units of time)\n",
    "    a: amplitude (units of absorbance or concentration)\n",
    "    tau: lifetime (units of time)\n",
    "    o: offset (units of absorbance or concentration)\n",
    "    \"\"\"\n",
    "    if tau < 1.e-10 : \n",
    "        print('ERROR: choose a value of tau greater than zero')\n",
    "        return 0.\n",
    "    return a * np.exp(-t/tau) + o\n",
    "\n",
    "def fit_ta_data(file_dict, yaxis = 'TA1 [mOD]', verbose = False, semilog = False):\n",
    "    \"\"\" \n",
    "    Perform the fit of transient absorption decay curves using an exponential \n",
    "    functions plus offset. \n",
    "\n",
    "    Input parameters: \n",
    "    file_dict: a dictionary with information on the file with the data (path and name) and\n",
    "               adjustable parameters related to the fit:\n",
    "               time_skip : initial transient regime to remove from the fit\n",
    "               C0_guess, k_guess, offset_guess: starting guess of fitting parameters\n",
    "    yaxis : the column of the dataframe to use for the fit\n",
    "    verbose : if True plot the filtered data and the corresponding fit\n",
    "    semilog : if True, plot in semilogy scale\n",
    "\n",
    "    Action: \n",
    "           Filter the data by removing the initial time_skip part of the curve\n",
    "           Fit according to an exponential decay\n",
    "           Save the optimized values of the parameters and their standard errors in file_dict\n",
    "           Save the fitted curve in the file_dict['data'] DataFrame\n",
    "    \"\"\"   \n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    xaxis = 'Laser Delay [ns]'\n",
    "        \n",
    "    file_dict['filtered_data'] = file_dict['data'][file_dict['data']['Laser Delay [ns]']>file_dict['time_skip']].copy()\n",
    "    x = file_dict['filtered_data'][xaxis]\n",
    "    y = file_dict['filtered_data'][yaxis]\n",
    "\n",
    "    funct = exponential\n",
    "    p0 = (file_dict['DA0_guess'],file_dict['tau_guess'],file_dict['offset_guess'])\n",
    "    params, cv = scipy.optimize.curve_fit(funct,x,y,p0)\n",
    "\n",
    "    file_dict['DA0'] = params[0]\n",
    "    file_dict['DA0_SE'] = np.sqrt(cv[0,0])\n",
    "    file_dict['tau'] = params[1]\n",
    "    file_dict['tau_SE'] = np.sqrt(cv[1,1])\n",
    "    file_dict['offset'] = params[2] \n",
    "    file_dict['offset_SE'] = np.sqrt(cv[2,2])\n",
    "\n",
    "    file_dict['filtered_data']['TA_fitted'] = funct(x,params[0],params[1],params[2])\n",
    "\n",
    "    if verbose :\n",
    "        if semilog :\n",
    "            plt.semilogy(x,y,label=yaxis)\n",
    "            plt.semilogy(x,funct(x,params[0],params[1],params[2]),label='Fit')\n",
    "        else :\n",
    "            plt.plot(x,y,label=yaxis)\n",
    "            plt.plot(x,funct(x,params[0],params[1],params[2]),label='Fit')\n",
    "        plt.ylabel('Transient Absorption [mOD]')\n",
    "        plt.xlabel('Laser Delay [ns]')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below are incomplete and will need to be completed by the student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_average_TA(file_dict):\n",
    "    \"\"\"\n",
    "    Average all the TA runs recorded in a TA .csv file.\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Create a new column in the file_dict['data'] component of the input with the average\n",
    "        of the TA runs recorded in the file\n",
    "    \"\"\"\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    columns = file_dict['data'].columns.drop('Laser Delay [ns]')\n",
    "    if 'TAaverage' in file_dict['data'].columns: \n",
    "        columns = columns.drop('TAaverage')\n",
    "    # the variable columns is a list that contains the columns of the dataframe you need to average\n",
    "    file_dict['data']['TAaverage'] = 0 # 0 is NOT the right result, THIS NEEDS TO BE COMPLETED BY THE STUDENT\n",
    "    return\n",
    "\n",
    "def calc_max_TA(file_dict):\n",
    "    \"\"\"\n",
    "    Given a file dictionary with the average TA, find the maximum value of the transient absorption \n",
    "    and the Laser Delay at which this value occurs\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        \n",
    "    \"\"\"\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "    if not ('TAaverage' in file_dict['data'].columns): \n",
    "        calc_average_TA(file_dict)\n",
    "    # below you should compute the maximum value of the transient absorption in the TAaverage column        \n",
    "    file_dict['TAmax'] = 0 # 0 is NOT the right result, THIS NEEDS TO BE COMPLETED BY THE STUDENT\n",
    "    # below you should compute the Laser Delay that corresponds to the maximum of transient absorption\n",
    "    file_dict['LD_TAmax'] = 0 # 0 is NOT the right result, THIS NEEDS TO BE COMPLETED BY THE STUDENT\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Systems {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following module needs to be installed on Colab. We won't need it too much for this analysis, but they offer a lot of nice features for chemistry programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install and load RDKit { display-mode: \"form\" }\n",
    "!pip install rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "!pip install cirpy\n",
    "import cirpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular we can use them to draw the molecules in our experiments. While for some molecules you can just write their names and RDKit will plot them, for most molecules you will need to provide their SMILES or their CAS numbers. Luckily, CIRpy can usually find SMILES for you, if you type the common name correctly or if you know the CAS number. \n",
    "\n",
    "These are the CAS numbers for the molecule in your TA experiments:\n",
    "* ZnTPP (5,10,15,20-Tetraphenyl-21H,23H-porphine zinc): CAS 14074-80-7\n",
    "* Fullerene C70: CAS 115383-22-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Choose the molecule to draw { display-mode: \"form\" }\n",
    "input = '5,10,15,20-Tetraphenyl-21H,23H-porphine zinc' # @param {type:\"string\"}\n",
    "input_type = 'name' # @param [\"smiles\", \"name\", \"cas\"] {allow-input: true}\n",
    "if input_type != 'smiles' :\n",
    "    smiles=cirpy.resolve( input, 'smiles')\n",
    "else:\n",
    "    smiles=input\n",
    "img = Draw.MolToImage( Chem.MolFromSmiles(smiles), size=(300, 300) )\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the Google Drive and access an example of a dataset from a kinetics experiment. You can use the same set that I am using by downloading it from Canvas, [here](). Or you can use your own files. I am assuming the file in question will be located in a `Kinetics_Data/` subfolder in your `Colab Notebook/` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set Local Path { display-mode: \"form\" }\n",
    "# The following needs to be the path of the folder with all your collected data in .csv format\n",
    "local_path=\"Colab Notebooks/TA_Data/\" # @param {type:\"string\"}\n",
    "path = base_path+local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to streamline the fitting of the data, we will be storing the information that corresponds to each TA file into a Python dictionary (`dict`), together with all the relevant information of that experiment and the parameters that we need for the fit. You can use the same statement in the following, but make sure to change the file name from 'TA_traces.csv' (the one that I am using) to the one you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = {'path':path, 'name':'TA_traces.csv', 'label':'Run1', '[ZnTPP]': 0.2, '[C70]':0., 'time_skip':0, 'DA0_guess':1., 'tau_guess':1., 'offset_guess':0.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the data into each dictionary as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_file_dict(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a new component of the dictionary named 'data', which will contain a DataFrame generated from the DSC file specified in the dictionary. We should always check that the loaded data looks ok, say by checking the number of columns and rows and, maybe, plotting the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1['data'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1['data'].plot('Laser Delay [ns]','TA1 [mOD]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we created a set of tools to load the data and plot them in one step. For a single dictionary you can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_dict(file1,'TA3 [mOD]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you want to all the columns in your data in the same plot, you can specify 'all' as an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_dict(file1,'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first task of the worksheet will ask you to compute the average of the different TA runs that are recorded in the file. This task is implemented in a function at the beginning of this notebook, but you will need to figure out how to do the average of multiple columns of a dataframe. You can try to implement the calculation in the following box and see if you can compute the average between the first two columns of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1['data'][['TA1 [mOD]','TA2 [mOD]']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have figured out a command that works on the case above, try to implement it in the function `calc_average_TA()` that is implemented at the beginning of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_average_TA(file1)\n",
    "plot_file_dict(file1,'TAaverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the Analysis Parameters {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Adjust the parameters for the non-linear fit { display-mode: \"form\" }\n",
    "yaxis = 'TA1 [mOD]' # @param ['TAaverage','TA1 [mOD]','TA2 [mOD]']\n",
    "time_skip = 0 # @param {type:\"number\"}\n",
    "DA0_guess = 100. # @param {type:\"number\"}\n",
    "tau_guess = 1000 # @param {type:\"number\"}\n",
    "offset_guess = 0. # @param {type:\"number\"}\n",
    "semilog = False # @param {type:\"boolean\"}\n",
    "file1['time_skip'] = time_skip\n",
    "file1['DA0_guess'] = DA0_guess\n",
    "file1['tau_guess'] = tau_guess\n",
    "file1['offset_guess'] = offset_guess\n",
    "fit_ta_data(file1, yaxis=yaxis, verbose=True, semilog=semilog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The transient lifetime is {file1['tau']:6.2f} ns and its associated standard error is {file1['tau_SE']:4.2f} ns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Each of Your Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat this analysis for each one of your files. Make sure to take note of the parameters that affect your analysis the most, you will need them in your worksheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Adjust the parameters for each of your files { display-mode: \"form\" }\n",
    "filename = 'TA_traces.txt' # @param {type:\"string\"}\n",
    "yaxis = 'TA1 [mOD]' # @param ['TAaverage','TA1 [mOD]','TA2 [mOD]']\n",
    "time_skip = 0 # @param {type:\"number\"}\n",
    "DA0_guess = 100. # @param {type:\"number\"}\n",
    "tau_guess = 1000 # @param {type:\"number\"}\n",
    "offset_guess = 0. # @param {type:\"number\"}\n",
    "semilog = True # @param {type:\"boolean\"}\n",
    "newfile = {'path':path, 'name':filename, 'label':'Run1', '[ZnTPP]': 0.2, '[C70]':0., 'time_skip':time_skip, 'DA0_guess':DA0_guess, 'tau_guess':tau_guess, 'offset_guess':offset_guess} \n",
    "load_data_to_file_dict(newfile)\n",
    "calc_average_TA(newfile)\n",
    "fit_ta_data(file1,yaxis=yaxis,verbose=True, semilog=semilog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
