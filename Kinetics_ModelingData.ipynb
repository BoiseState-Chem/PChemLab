{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr Oliviero Andreussi, olivieroandreuss@boisestate.edu\n",
    "\n",
    "Boise State University, Department of Chemistry and Biochemistry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and Data Analysis for the Kinetics of Methylene Blue RedOx Experiment {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Setup {-}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let us import the main modules that we will need for this lecture. You may see some new modules in the list below, we will add more details in the right sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Notebook Setup { display-mode: \"form\" }\n",
    "# Import the main modules used in this worksheet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import scipy.optimize\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load the google drive with your files \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# The following needs to be the path of the folder with all your datafile in .csv format\n",
    "base_path = '/content/drive/MyDrive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions to load the data { display-mode: \"form\" }\n",
    "def load_data_to_file_dict(file_dict):\n",
    "    \"\"\"\n",
    "    Load a uv-vis .csv file. \n",
    "    The format of the file should have two rows of headers and two columns of data (time and absorbance)\n",
    "    The file may have additional information from the instrument saved at the bottom\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Add to file_dict a Pandas DataFrame with two columns: time (in seconds) and absorbance (in input units)   \n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_dict['path']+file_dict['name'],header=1,usecols=(0,1)).apply(pd.to_numeric,errors='coerce').dropna()\n",
    "    data = data[data['Abs']>0.]\n",
    "    if data.keys()[0] == 'Time (sec)' :\n",
    "        data = data.rename(columns={'Time (sec)':'time'})\n",
    "    elif data.keys()[0] == 'Time (min)' :\n",
    "        data['time'] = data['Time (min)'] * 60\n",
    "        data = data.drop('Time (min)',axis=1)\n",
    "    data = data.rename(columns={'Abs':'absorbance'})\n",
    "    file_dict['data'] = data\n",
    "    return\n",
    "\n",
    "def load_data_to_file_list(file_list):\n",
    "    \"\"\"\n",
    "    Given a list of dictionary files, recursively use load_data_to_file_dict to load the data into each of the dictionaries\n",
    "\n",
    "    Input variables:\n",
    "        file_list : a list of dictionary files, each with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "    \n",
    "    Action: \n",
    "        Add to each file_dict a Pandas DataFrame with two columns: time (in seconds) and temperature (in input units)   \n",
    "    \"\"\"\n",
    "    for f in file_list : \n",
    "        if not ('data' in f): load_data_to_file_dict(f)\n",
    "    return\n",
    "\n",
    "def plot_file_dict(file_dict, semilog=False, with_fit=False):\n",
    "    \"\"\"\n",
    "    Given a dictionary file of a bomb calorimetry experiment, plot temperature vs. time.\n",
    "\n",
    "    Input variables:\n",
    "        file_dict : a dictionary file with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "        semilog : use a logarithmic scale for the absorbance axis\n",
    "        with_fit : plot the fitted curve, if present\n",
    "    \n",
    "    Action: \n",
    "        Plot absorbance vs. time for the selected file \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(f)\n",
    "    if semilog :\n",
    "        plt.semilogy(file_dict['data']['time'],file_dict['data']['absorbance'],label=file_dict['label'])\n",
    "        if with_fit and 'absorbance_fitted' in file_dict['data'].keys(): \n",
    "            plt.semilogy(file_dict['data']['time'],file_dict['data']['absorbance_fitted'],':',label=file_dict['label']+' fit')\n",
    "    else:\n",
    "        plt.plot(file_dict['data']['time'],file_dict['data']['absorbance'],label=file_dict['label'])\n",
    "        if with_fit and 'absorbance_fitted' in file_dict['data'].keys(): \n",
    "            plt.plot(file_dict['data']['time'],file_dict['data']['absorbance_fitted'],':',label=file_dict['label']+' fit')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Absorbance (a.u.)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_file_list(file_list,key='',value=[''],semilog=False,with_fit=False):\n",
    "    \"\"\"\n",
    "    Given a list of dictionary files, plot absorbance vs. time for each file into the same plot.\n",
    "    If key/value are specified, only plot the files for which the key has the specified value.\n",
    "\n",
    "    Input variables:\n",
    "        file_list : a list of dictionary files, each with 'path' and 'name' keys corresponding to the file to be loaded\n",
    "        key: a string with the name of the key to shortlist the files\n",
    "        value: the value of the key used to select the shortlist of files\n",
    "    \n",
    "    Action: \n",
    "        Plot absorbance vs. time for the selected files  \n",
    "    \"\"\"\n",
    "    if value == '' or key == '':\n",
    "        file_shortlist = file_list\n",
    "    else :\n",
    "        file_shortlist = [f for f in file_list if f[key] in value ]\n",
    "    fig, ax = plt.subplots()\n",
    "    for i,f in enumerate(file_shortlist) : \n",
    "        color='C'+str(i)\n",
    "        if not ('data' in f): \n",
    "            load_data_to_file_dict(f)\n",
    "        if semilog :\n",
    "            plt.semilogy(f['data']['time'],f['data']['absorbance'],color=color,label=f['label'])\n",
    "            if with_fit and 'absorbance_fitted' in f['data'].keys(): \n",
    "                plt.semilogy(f['data']['time'],f['data']['absorbance_fitted'],':',color=color,label=f['label']+' fit')\n",
    "        else:\n",
    "            plt.plot(f['data']['time'],f['data']['absorbance'],color=color,label=f['label'])\n",
    "            if with_fit and 'absorbance_fitted' in f['data'].keys(): \n",
    "                plt.plot(f['data']['time'],f['data']['absorbance_fitted'],':',color=color,label=f['label']+' fit')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Absorbance (a.u.)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Functions to fit the data { display-mode: \"form\" }\n",
    "def linear(t, a, k, o):\n",
    "    \"\"\" \n",
    "    Function that returns a linear decaying function that saturates to an offset\n",
    "    f(t) = o + a - k * t (for t < a/k) or o (for t > a/k)\n",
    "\n",
    "    input variables\n",
    "    t: input value (units of time)\n",
    "    a: amplitude (units of absorbance or concentration)\n",
    "    k: decay rate (units of 1/time)\n",
    "    o: offset (units of absorbance or concentration)\n",
    "    \"\"\"\n",
    "    filter = t < a/k\n",
    "    return o + filter * (a - k * t)\n",
    "\n",
    "def exponential(t, a, k, o):\n",
    "    \"\"\" \n",
    "    Function that returns an exponentially decaying function plus offset\n",
    "    f(t) = o + a*e^(-k*t)\n",
    "\n",
    "    input variables\n",
    "    t: input value (units of time)\n",
    "    a: amplitude (units of absorbance or concentration)\n",
    "    k: decay rate (units of 1/time)\n",
    "    o: offset (units of absorbance or concentration)\n",
    "    \"\"\"\n",
    "    return a * np.exp(-k*t) + o\n",
    "\n",
    "def inverse(t, a, k, o):\n",
    "    \"\"\" \n",
    "    Function that returns a inverse decaying function plus offset\n",
    "    f(t) = o + 1/(1/a + 2*k*t) \n",
    "\n",
    "    input variables\n",
    "    t: input value (units of time)\n",
    "    a: amplitude (units of absorbance or concentration)\n",
    "    k: decay rate (units of 1/time)\n",
    "    o: offset (units of absorbance or concentration)\n",
    "    \"\"\"\n",
    "    return o + 1/(1/a+2*k*t)\n",
    "\n",
    "# Functions designed for fit the kinetics data\n",
    "def fit_kinetic(file_dict):\n",
    "    \"\"\" \n",
    "    Perform the fit of kinetic decay curves (uv-vis absorption spectra) using non-linear\n",
    "    functions plus offset. \n",
    "\n",
    "    Input parameters: \n",
    "    file_dict: a dictionary with information on the file with the data (path and name) and\n",
    "               adjustable parameters related to the fit:\n",
    "               time_skip : initial transient regime to remove from the fit\n",
    "               order: order of the kinetics to fit (zeroth, first, or second)\n",
    "               MB0_guess, k_guess, offset_guess: starting guess of fitting parameters\n",
    "\n",
    "    Action: \n",
    "           Filter the data by removing the initial time_skip part of the curve\n",
    "           Fit one of three non-linear regimes according to the specified order (linear, exponential, inverse)\n",
    "           Save the optimized values of the parameters and their standard errors in file_dict\n",
    "           Save the fitted curve in the file_dict['data'] DataFrame\n",
    "    \"\"\"   \n",
    "    if not ('data' in file_dict): \n",
    "        load_data_to_file_dict(file_dict)\n",
    "        \n",
    "    filtered_data = file_dict['data'][file_dict['data']['time']>file_dict['time_skip']]\n",
    "    x = filtered_data['time']\n",
    "    y = filtered_data['absorbance']\n",
    "\n",
    "    if file_dict['order'] == 'zeroth' :\n",
    "        funct = linear\n",
    "    elif file_dict['order'] == 'first' :\n",
    "        funct = exponential\n",
    "    elif file_dict['order'] == 'second' :\n",
    "        funct = inverse\n",
    "\n",
    "    p0 = (file_dict['MB0_guess'],file_dict['k_guess'],file_dict['offset_guess'])\n",
    "    params, cv = scipy.optimize.curve_fit(funct,x,y,p0)\n",
    "\n",
    "    file_dict['MB0'] = params[0]\n",
    "    file_dict['MB0_SE'] = np.sqrt(cv[0,0])\n",
    "    file_dict['k'] = params[1]\n",
    "    file_dict['k_SE'] = np.sqrt(cv[1,1])\n",
    "    file_dict['offset'] = params[2] \n",
    "    file_dict['offset_SE'] = np.sqrt(cv[2,2])\n",
    "\n",
    "    file_dict['data']['absorbance_fitted'] = funct(file_dict['data']['time'],params[0],params[1],params[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Systems {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following module needs to be installed on Colab. We won't need it too much for this analysis, but they offer a lot of nice features for chemistry programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install and load RDKit { display-mode: \"form\" }\n",
    "!pip install rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "!pip install cirpy\n",
    "import cirpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular we can use them to draw the molecules in our experiments. While for some molecules you can just write their names and RDKit will plot them, for most molecules you will need to provide their SMILES or their CAS numbers. Luckily, CIRpy can usually find SMILES for you, if you type the common name correctly or if you know the CAS number. \n",
    "\n",
    "These are the SMILES for the molecules in your kinetics experiments:\n",
    "* Methylene Blue: '[Cl-].CN(C)c1ccc2nc3ccc(cc3[s+]c2c1)N(C)C'\n",
    "* Leucomethylene Blue: 'CN(C)c1ccc2Nc3ccc(cc3Sc2c1)N(C)C'\n",
    "* Ascrobic Acid: 'OCC(O)C1OC(=C(O)C1=O)O'\n",
    "* Ascorbate: 'OC[C@H](O)[C@H]1OC(=O)[C-](O)C1=O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Choose the molecule to draw { display-mode: \"form\" }\n",
    "input = 'ascorbate' # @param {type:\"string\"}\n",
    "input_type = 'name' # @param [\"smiles\", \"name\", \"cas\"] {allow-input: true}\n",
    "if input_type != 'smiles' :\n",
    "    smiles=cirpy.resolve( input, 'smiles')\n",
    "else:\n",
    "    smiles=input\n",
    "img = Draw.MolToImage( Chem.MolFromSmiles(smiles), size=(300, 300) )\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the Google Drive and access an example of a dataset from a kinetics experiment. You can use the same set that I am using by downloading it from Canvas, [here](). Or you can use your own files. I am assuming the file in question will be located in a `Kinetics_Data/` subfolder in your `Colab Notebook/` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set Local Path { display-mode: \"form\" }\n",
    "# The following needs to be the path of the folder with all your collected data in .csv format\n",
    "local_path=\"Colab Notebooks/Kinetics_Data/\" # @param {type:\"string\"}\n",
    "path = base_path+local_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to streamline the fitting of the data, we will be storing the file that corresponds to each experiment into a Python dictionary (`dict`), together with all the relevant information of that experiment and the parameters that we need for the fit. You can use the same statement in the following, but make sure to change the file name from 'SetArun1.csv' (the one that I am using) to the one you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = {'path':path, 'name':'SetArun1.csv', 'label':'Run1', 'set':'A', '[MB]': 0.1, '[AA]': 0.1, '[HCl]': 0.1, 'pH': 1, 'order': 'first', 'MB0_guess': 1., 'k_guess': 1., 'offset_guess': 0.1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_to_file_dict(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should always check that the loaded data looks ok, say by checking the number of columns and rows and, maybe, plotting the two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1['data'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_dict(file1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the same data using a semilog plot (with the y-axis in log scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_dict(file1,semilog=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to Fit with Simple Linear Regression {-}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice if we could just use the linear regression algorithm that we have used before to fit the kinetics curves. However, one of our tasks requires to identify the order of the reaction with respect to the concentration of methylene blue (abbreviated in $[MB]$ in the following). Different orders of kinetics correspond to different decay curves. \n",
    "* A reaction that is of zeroth order will have a linear decay in $[MB]$, i.e. $[MB](t)=[MB0]-kt$\n",
    "* A reaction that is of first order will have an exponential decay in $[MB]$, i.e. $[MB](t)=[MB0]e^{-kt}$\n",
    "* A reaction that is of second order will have a decay inversile proportional to $[MB]$, i.e. $[MB](t)=\\frac{1}{1/[MB0]+kt}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principles, if we make the appropriate change of variables, we can linearize all three of the above equations and try to use linear regression to perform the fit of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroth_order=LinearRegression()\n",
    "x=file1['data']['time'].values.reshape(-1,1)\n",
    "y=file1['data']['absorbance'].values\n",
    "zeroth_order.fit(x,y)\n",
    "plt.plot(x,y)\n",
    "plt.plot(x,zeroth_order.predict(x))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Absorbance (arbitrary units)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you try to fit the same data using a first order or a second order model? You will need to change the definition of the dependent variable to make the linear fit appropriate. For the first order you want to fit $log([MB])$ while for the second order model you want to fit $1/[MB]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_order=LinearRegression()\n",
    "x=file1['data']['time'].values.reshape(-1,1)\n",
    "y=np.log(file1['data']['absorbance'].values)\n",
    "first_order.fit(x,y)\n",
    "plt.plot(x,np.exp(y))\n",
    "plt.plot(x,np.exp(first_order.predict(x)))\n",
    "#plt.semilogy(x,np.exp(y))\n",
    "#plt.semilogy(x,np.exp(first_order.predict(x)))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Absorbance (arbitrary units)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the models works the best? Is any of the model giving a decent fit of the data? Why or why not? Is the linearization trick always appropriate? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Fit using Scipy {-} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the possible causes of poor fitting is the fact that our experimental results do not go to zero exactly, but they converge to a baseline, i.e. there is an offset in the data. Unfortunately the offset is tricky to remove and it makes the linearization trick fail. However, we can still try to fit using a non-linear model. The algorithm that optimize an arbitrary model, even those that are non-linear in the parameters, are a bit more tricky to use. They are not able to get the optimal solution directly, but rather they need to optimize the solution one step at the time. The starting point of the algorithm is usually important to ensure convergence and that we get to the best set of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Try alternative non-linear fits { display-mode: \"form\" }\n",
    "order = 'first' # @param ['zeroth', 'first', 'second'] {allow-input: true}\n",
    "semilog = False # @param {type:\"boolean\"}\n",
    "time_skip = 0 # @param {type:\"number\"}\n",
    "\n",
    "MB0 = 0.5 # @param {type:\"number\"}\n",
    "k = 0.1 # @param {type:\"number\"}\n",
    "offset = 0.05 # @param {type:\"number\"}\n",
    "p0 = (MB0, k, offset) # this are the starting values of the parameters of the function\n",
    "\n",
    "if order == 'zeroth' :\n",
    "    funct = linear\n",
    "elif order == 'first' :\n",
    "    funct = exponential\n",
    "elif order == 'second' : \n",
    "    funct = inverse\n",
    "\n",
    "# filter and fit the data\n",
    "filtered_data = file1['data'][file1['data']['time']>time_skip]\n",
    "x = filtered_data['time']\n",
    "y = filtered_data['absorbance']\n",
    "params, cv = scipy.optimize.curve_fit(funct,x,y,p0)\n",
    "\n",
    "# plot the data together with the fit\n",
    "if semilog : \n",
    "    plt.semilogy(file1['data']['time'],file1['data']['absorbance'])\n",
    "    plt.semilogy(file1['data']['time'],funct(file1['data']['time'],params[0],params[1],params[2]))\n",
    "else:\n",
    "    plt.plot(file1['data']['time'],file1['data']['absorbance'])\n",
    "    plt.plot(file1['data']['time'],funct(file1['data']['time'],params[0],params[1],params[2]))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Absorbance (arbitrary units)')\n",
    "plt.show()\n",
    "\n",
    "# compute correlation coefficient\n",
    "RSS = np.sum((y-funct(x,params[0],params[1],params[2]))**2)\n",
    "TSS = np.sum((y-y.mean())**2)\n",
    "R2 = 1-RSS/TSS\n",
    "\n",
    "# print results\n",
    "print(f\"The optimized values of the parameters are: \\nMB0 = {params[0]:6.4f}, k = {params[1]:6.4f}, offset = {params[2]:6.4f}\")\n",
    "print(f\"The standard errors on these parameters are: \\nSE_MBO = {np.sqrt(cv[0,0]):6.4f}, SE_k = {np.sqrt(cv[1,1]):6.4f}, SE_offset = {np.sqrt(cv[2,2]):6.4f}\")\n",
    "print(f\"The R2 of the fit on the used data is {R2:8.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit returns two objects, which we labeled `params` and `cv`:\n",
    "* the first one contains the value of the optimal parameters, those that give the smallest deviation from the experimental curve\n",
    "* the second object contains the covariance matrix of the parameters: the diagonal of this matrix has the variance in the estimate of the parameter, which you can use as an error estimate for your parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Each of Your Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the analysis above for each one of your curves. Make sure to take note of the important parameters that affect your analysis the most (e.g. `time_skip` and the starting values of the fitting parameters), you will need them in your worksheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Check the parameters on each of your files { display-mode: \"form\" }\n",
    "name = 'SetBrun3.csv' # @param {type:\"string\"}\n",
    "order = 'first' # @param ['zeroth', 'first', 'second'] {allow-input: true}\n",
    "semilog = False # @param {type:\"boolean\"}\n",
    "time_skip = 40 # @param {type:\"number\"}\n",
    "\n",
    "MB0 = 0.5 # @param {type:\"number\"}\n",
    "k = 0.1 # @param {type:\"number\"}\n",
    "offset = 0.05 # @param {type:\"number\"}\n",
    "p0 = (MB0, k, offset) # this are the starting values of the parameters of the function\n",
    "\n",
    "newfile = {'path':path, 'name':name, 'set':'', '[MB]': 1, '[AA]': 1, '[HCl]': 1, 'pH': 1, 'order': order, 'MB0_guess': MB0, 'k_guess': k, 'offset_guess': offset }\n",
    "load_data_to_file_dict(newfile)\n",
    "\n",
    "if order == 'zeroth' :\n",
    "    funct = linear\n",
    "elif order == 'first' :\n",
    "    funct = exponential\n",
    "elif order == 'second' : \n",
    "    funct = inverse\n",
    "\n",
    "# filter and fit the data\n",
    "filtered_data = newfile['data'][newfile['data']['time']>time_skip]\n",
    "x = filtered_data['time']\n",
    "y = filtered_data['absorbance']\n",
    "params, cv = scipy.optimize.curve_fit(funct,x,y,p0)\n",
    "\n",
    "# plot the data together with the fit\n",
    "if semilog : \n",
    "    plt.semilogy(newfile['data']['time'],newfile['data']['absorbance'])\n",
    "    plt.semilogy(newfile['data']['time'],funct(newfile['data']['time'],params[0],params[1],params[2]))\n",
    "else:\n",
    "    plt.plot(newfile['data']['time'],newfile['data']['absorbance'])\n",
    "    plt.plot(newfile['data']['time'],funct(newfile['data']['time'],params[0],params[1],params[2]))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Absorbance (arbitrary units)')\n",
    "plt.show()\n",
    "\n",
    "# compute correlation coefficient\n",
    "RSS = np.sum((y-funct(x,params[0],params[1],params[2]))**2)\n",
    "TSS = np.sum((y-y.mean())**2)\n",
    "R2 = 1-RSS/TSS\n",
    "\n",
    "# print results\n",
    "print(f\"The optimized values of the parameters are: \\nMB0 = {params[0]:6.4f}, k = {params[1]:6.4f}, offset = {params[2]:6.4f}\")\n",
    "print(f\"The standard errors on these parameters are: \\nSE_MBO = {np.sqrt(cv[0,0]):6.4f}, SE_k = {np.sqrt(cv[1,1]):6.4f}, SE_offset = {np.sqrt(cv[2,2]):6.4f}\")\n",
    "print(f\"The R2 of the fit on the used data is {R2:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond \"Simple\" Rate Laws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three equations that we tested in the notebook are derived assuming a single-compound rate law with order 0, 1, or 2 in the concentration of the studied molecule. This approximation allows to get analytical expressions for the concentration over time, but it relies on a single rate limiting reaction step and in being in flooding conditions for all other compounds involved in the kinetics. How can we study a more complicated set of chemical equations and the effect of the concentration of other compounds?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume our kinetics involve a main reaction:\n",
    "\n",
    "$$A + B \\rightleftharpoons C \\tag{1}$$ \n",
    "\n",
    "which in our case would correspond to methylene blue (A) reacting with electrons and protons (B) to give leukomethylene blue (C). Let's now consider the possibility that our product reacts with another compound in solution to revert to its oxydized form:\n",
    "\n",
    "$$C + D \\rightleftharpoons A \\tag{2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume that reaction (1) has a forward and backward rate constant of $k_1^f$ and $k_1^b$, while reaction (2) has forward and backward rate constants of $k_2^f$ and $k_2^b$, we can write four equations that control the behavior of the concentrations of compounds A-D as a function of time. Namely for $[A](t)\\equiv [A]$ we have\n",
    "$$ \\frac{d[A]}{dt}=-k_1^f [A][B]+k_1^b[C]-k_2^b[A]+k_2^f[C][D] $$\n",
    "and similarly for $[C](t)\\equiv [C]$ \n",
    "$$ \\frac{d[C]}{dt}=k_1^f [A][B]-k_1^b[C]+k_2^b[A]-k_2^f[C][D] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will end up with four coupled first order ordinary differential equations (i.e., equations that involve functions of a single variable and their first derivatives) that are nonlinear (i.e., the right-hand sides have products between the functions or have functions raised to some power different from 1). There is no simple analytical way to get solutions, but we can numerically integrate these equations. This means setting the initial concentrations and evolving them in time making very small timesteps. This process is so useful in scientific applications that SciPy has a tool for this called `odeint()`. In order to use it, we need to create a function that embeds the variables and the connected ODEs that we want to solve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system of coupled ODEs\n",
    "def methyleneblue_kinetics(y, t, k1f, k1b, k2f, k2b):\n",
    "    \"\"\"\n",
    "    Defines the system of coupled first-order ODEs for the kinetic reactions:\n",
    "    a + b <-> c (forward constant k1f, backward constant k1b)\n",
    "    c + d <-> a (forward constant k2f, backward constant k2b)\n",
    "    \n",
    "    Args:\n",
    "        y (list): List of dependent variables [a, b, c, d].\n",
    "        t (float): Independent variable (time).\n",
    "        k1f, k1b, k2f, k2b (float): Parameters of the system.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of derivatives [da/dt, db/dt, dc/dt, dd/dt].\n",
    "    \"\"\"\n",
    "    a, b, c, d = y\n",
    "    dadt = -k1f*a*b + k1b*c + k2f*c*d - k2b*a\n",
    "    dbdt = -k1f*a*b + k1b*c \n",
    "    dcdt = k1f*a*b - k1b*c - k2f*c*d + k2b*a\n",
    "    dddt = -k2f*c*d + k2b*a\n",
    "    dydt = [dadt, dbdt, dcdt, dddt]\n",
    "    return dydt\n",
    "\n",
    "def methyleneblue_kinetics_constantD(y, t, k1f, k1b, k2f, k2b):\n",
    "    \"\"\"\n",
    "    Defines the system of coupled first-order ODEs for the kinetic reactions:\n",
    "    a + b <-> c (forward constant k1f, backward constant k1b)\n",
    "    c + d <-> a (forward constant k2f, backward constant k2b)\n",
    "    \n",
    "    Args:\n",
    "        y (list): List of dependent variables [a, b, c, d].\n",
    "        t (float): Independent variable (time).\n",
    "        k1f, k1b, k2f, k2b (float): Parameters of the system.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of derivatives [da/dt, db/dt, dc/dt, dd/dt].\n",
    "    \"\"\"\n",
    "    a, b, c, d = y\n",
    "    dadt = -k1f*a*b + k1b*c + k2f*c*d - k2b*a\n",
    "    dbdt = -k1f*a*b + k1b*c \n",
    "    dcdt = k1f*a*b - k1b*c - k2f*c*d + k2b*a\n",
    "    dddt = 0 # here we assume [D] is constant\n",
    "    dydt = [dadt, dbdt, dcdt, dddt]\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sake of reducing the number of parameters that we can play with, let's just assume we only have forward reactions, i.e., the rates for the backward reactions are significantly smaller than the ones of the forward reactions $k^b=10^{-5}\\cdot k^f$. We will also take the starting concentration of the main reactant to be one and that the starting concentration of the product is zero, i.e., $[A](t=0)=1$ and $[C](t=0)=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Check the parameters on each of your files { display-mode: \"form\" }\n",
    "from scipy.integrate import odeint\n",
    "# Set rate constants\n",
    "k1f = 1e-0 #@param {type:\"number\"}\n",
    "k1b = 1e-5*k1f\n",
    "k2f = 1e-0 #@param {type:\"number\"}\n",
    "k2b = 1e-5*k2f \n",
    "constants = (k1f, k1b, k2f, k2b)\n",
    "\n",
    "# Set initial concentrations\n",
    "a0 = 1.0 \n",
    "b0 = 2.0 #@param {type:\"number\"}\n",
    "c0 = 0.0 \n",
    "d0 = 0.1 #@param {type:\"number\"}\n",
    "y0 = [a0, b0, c0, d0]  # Initial values for the concentrations\n",
    "\n",
    "constant_D = True #@param {type:\"boolean\"}\n",
    "semilog = False #@param {type:\"boolean\"}\n",
    "\n",
    "# Time points for the solution\n",
    "t = np.linspace(0, 10, 100)\n",
    "\n",
    "# Solve the ODEs\n",
    "if constant_D:\n",
    "    sol = odeint(methyleneblue_kinetics_constantD, y0, t, args=constants)\n",
    "else:\n",
    "    sol = odeint(methyleneblue_kinetics, y0, t, args=constants)\n",
    "\n",
    "# Extract the solutions for x and z\n",
    "a = sol[:, 0]\n",
    "c = sol[:, 2]\n",
    "d = sol[:, 3]\n",
    "\n",
    "# Plot the results\n",
    "if semilog:\n",
    "    plt.semilogy(t, a, label='[A](t)')\n",
    "    plt.semilogy(t, c, label='[C](t)')\n",
    "    plt.semilogy(t, d, label='[D](t)')\n",
    "else:\n",
    "    plt.plot(t, a, label='[A](t)')\n",
    "    plt.plot(t, c, label='[C](t)')\n",
    "    plt.plot(t, d, label='[D](t)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Concentrations (M)')\n",
    "plt.title('Solution of Coupled ODEs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
